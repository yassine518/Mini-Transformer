# Mini Transformer - Toy Copy Task Demo

This repository contains a **mini implementation of the Transformer model** ("Attention is All You Need") in PyTorch.  
The model is trained on a **toy copy task**, where it learns to replicate sequences of integers.

---

## Features

- Scaled dot-product attention with multi-head attention  
- Encoder and decoder layers  
- Gradient clipping to stabilize training  
- Start-of-sequence token handling for the decoder  
- Fixed dataset for deterministic overfitting demonstration  

